{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "LFC1ZIYN9krX"
   },
   "source": [
    "# 📚 ДЗ №2: Работа с данными для LLM\n",
    "\n",
    "## 🎯 Цель задания\n",
    "После выполнения задания вы сможете:\n",
    "- Предобрабатывать русскоязычные текстовые данные для LLM\n",
    "- Работать с готовыми моделями HuggingFace для анализа тональности и NER\n",
    "- Создавать эффективные промпты для LLM API\n",
    "- Сравнивать качество работы разных подходов к анализу текста\n",
    "- Формировать датасеты в формате instruction-following для fine-tuning\n",
    "- Сохранять данные в правильных форматах для обучения LLM\n",
    "\n",
    "## 📝 Структура задания\n",
    "- **Часть 1** (35% оценки): Предобработка данных и работа с готовыми моделями\n",
    "- **Часть 2** (35% оценки): LLM API и prompt engineering\n",
    "- **Часть 3** (20% оценки): Подготовка данных для fine-tuning LLM\n",
    "- **Часть 4** (10% оценки): Сравнительный анализ и визуализация\n",
    "\n",
    "## ⚡ Критерии оценки\n",
    "- Качество предобработки данных: 25%\n",
    "- Корректность работы с готовыми моделями: 20%\n",
    "- Эффективность промптов для LLM: 25%\n",
    "- Правильность подготовки данных для fine-tuning: 20%\n",
    "- Качество сравнительного анализа: 10%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "0AUM-rrP9kra"
   },
   "source": [
    "## 🔧 Установка зависимостей\n",
    "\n",
    "Установим необходимые библиотеки для работы с данными, готовыми моделями и LLM API.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NyEWF5Sx9kra",
    "ExecuteTime": {
     "end_time": "2025-08-24T08:39:29.605123Z",
     "start_time": "2025-08-24T08:39:10.212740Z"
    }
   },
   "source": [
    "%pip install pandas numpy matplotlib seaborn\n",
    "%pip install transformers torch\n",
    "%pip install openai>=1.0.0  # Для работы с OpenAI API\n",
    "%pip install datasets\n",
    "%pip install pymorphy2\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (2.3.1)\r\n",
      "Requirement already satisfied: numpy in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (2.3.2)\r\n",
      "Requirement already satisfied: matplotlib in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (3.10.5)\r\n",
      "Requirement already satisfied: seaborn in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (0.13.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from matplotlib) (4.59.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\r\n",
      "Requirement already satisfied: pillow>=8 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from matplotlib) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (4.55.2)\r\n",
      "Requirement already satisfied: torch in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (2.8.0)\r\n",
      "Requirement already satisfied: filelock in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from transformers) (3.19.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from transformers) (0.34.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from transformers) (2.3.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from transformers) (2025.7.34)\r\n",
      "Requirement already satisfied: requests in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from transformers) (2.32.4)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from transformers) (0.21.4)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from transformers) (0.6.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\r\n",
      "Requirement already satisfied: setuptools in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (80.9.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (12.8.93)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (12.8.90)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (12.8.90)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (12.8.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (11.3.3.83)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (10.3.9.90)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (11.7.3.90)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (12.5.8.93)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (2.27.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (12.8.90)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (12.8.93)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (1.13.1.3)\r\n",
      "Requirement already satisfied: triton==3.4.0 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from torch) (3.4.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from requests->transformers) (2025.8.3)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "zsh:1: 1.0.0 not found\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting datasets\r\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: filelock in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from datasets) (3.19.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from datasets) (2.3.2)\r\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\r\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\r\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\r\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: pandas in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from datasets) (2.3.1)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from datasets) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from datasets) (4.67.1)\r\n",
      "Collecting xxhash (from datasets)\r\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting multiprocess<0.70.17 (from datasets)\r\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\r\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from datasets) (0.34.4)\r\n",
      "Requirement already satisfied: packaging in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from datasets) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from datasets) (6.0.2)\r\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\r\n",
      "  Downloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\r\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\r\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\r\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\r\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\r\n",
      "  Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\r\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\r\n",
      "  Downloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\r\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\r\n",
      "  Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\r\n",
      "  Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\r\n",
      "Requirement already satisfied: idna>=2.0 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.14.1)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.7)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.3)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.8.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/dmitry/PyCharmMiscProject/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\r\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\r\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\r\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\r\n",
      "Downloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m4.9 MB/s\u001B[0m  \u001B[33m0:00:00\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\r\n",
      "Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\r\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\r\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\r\n",
      "Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\r\n",
      "Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\r\n",
      "Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.8/42.8 MB\u001B[0m \u001B[31m6.7 MB/s\u001B[0m  \u001B[33m0:00:06\u001B[0m6m0:00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\r\n",
      "Installing collected packages: xxhash, pyarrow, propcache, multidict, fsspec, frozenlist, dill, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\r\n",
      "\u001B[2K  Attempting uninstall: fsspecm\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m 3/13\u001B[0m [multidict]\r\n",
      "\u001B[2K    Found existing installation: fsspec 2025.7.0━━━━━━━━━━━━━━\u001B[0m \u001B[32m 3/13\u001B[0m [multidict]\r\n",
      "\u001B[2K    Uninstalling fsspec-2025.7.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m 3/13\u001B[0m [multidict]\r\n",
      "\u001B[2K      Successfully uninstalled fsspec-2025.7.0━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m 3/13\u001B[0m [multidict]\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13/13\u001B[0m [datasets]/13\u001B[0m [datasets]ess]\r\n",
      "\u001B[1A\u001B[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 datasets-4.0.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 multidict-6.6.4 multiprocess-0.70.16 propcache-0.3.2 pyarrow-21.0.0 xxhash-3.5.0 yarl-1.20.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pymorphy2\r\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Collecting dawg-python>=0.7.1 (from pymorphy2)\r\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\r\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting docopt>=0.6 (from pymorphy2)\r\n",
      "  Using cached docopt-0.6.2-py2.py3-none-any.whl\r\n",
      "Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\r\n",
      "Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.2/8.2 MB\u001B[0m \u001B[31m10.5 MB/s\u001B[0m  \u001B[33m0:00:00\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\r\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4/4\u001B[0m [pymorphy2]\r\n",
      "\u001B[1A\u001B[2KSuccessfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PD5VNHqd9krb",
    "ExecuteTime": {
     "end_time": "2025-08-24T08:41:08.192199Z",
     "start_time": "2025-08-24T08:41:03.448876Z"
    }
   },
   "source": [
    "# Импорт необходимых библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройка отображения\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Библиотеки загружены успешно!\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Библиотеки загружены успешно!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "e7r5Jlk39krb"
   },
   "source": [
    "## 📊 Часть 1: Предобработка данных и готовые модели (35% оценки)\n",
    "\n",
    "### Задание 1.1: Анализ \"грязного\" датасета\n",
    "\n",
    "Проанализируем реалистичный датасет с типичными проблемами: опечатки, разные регистры, лишние пробелы, эмодзи.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_-AGgKwj9krc",
    "ExecuteTime": {
     "end_time": "2025-08-24T09:17:07.958934Z",
     "start_time": "2025-08-24T09:17:07.943801Z"
    }
   },
   "source": [
    "# Создаем \"грязный\" датасет с типичными проблемами реальных данных\n",
    "# Включаем сложные случаи для демонстрации преимуществ LLM\n",
    "raw_reviews = [\n",
    "    # Простые случаи\n",
    "    \"отличный iphone 14 PRO!!!  купил в магазине  apple на тверской 😊. Камера супер#positive\",\n",
    "    \"УЖАСНОЕ обслуживание в сбербанке на красной площади.. менеджер иван петров вобще не помог(#negative\",\n",
    "\n",
    "    # Сарказм и ирония (сложно для классических моделей)\n",
    "    \"Спасибо огромное сотрудникам МТС за то что 3 часа держали меня в очереди! Просто восхитительно 👏#negative\",\n",
    "    \"Какой замечательный сервис в Пятерочке - касса сломалась прямо передо мной, а персонал даже не извинился#negative\",\n",
    "\n",
    "    # Смешанные эмоции\n",
    "    \"iPhone 13 хороший телефон, но цена кусается. В целом доволен покупкой в re:Store#neutral\",\n",
    "    \"Ресторан Белуга красивый и атмосфера приятная, но официант Максим был невнимателен#negative\",\n",
    "\n",
    "    # Сложная структура предложений\n",
    "    \"Хотя Tesla Model Y и дорогая машина, и сервис в Рольф Премиум иногда подводит, но в целом я очень доволен покупкой#positive\",\n",
    "    \"Не могу сказать что отель Ритц-Карлтон плохой, просто ожидал большего за такие деньги#neutral\",\n",
    "\n",
    "    # Контекстно-зависимые случаи\n",
    "    \"Заказал доставку в Яндекс.Еде из ресторана Дача на Рублевке - привезли холодное, но курьер Андрей был вежливый#positive\",\n",
    "    \"MacBook Pro 16 работает как часы уже год, покупал в iStore на Арбате у консультанта Елены#positive\",\n",
    "\n",
    "    # Неоднозначные случаи\n",
    "    \"Сходил в кинотеатр Октябрь посмотреть новый фильм Marvel - ну такое себе, но попкорн вкусный был#neutral\",\n",
    "    \"Обслуживание в банке ВТБ на Тверской оставляет желать лучшего, хотя менеджер Ольга старалась помочь#negative\",\n",
    "\n",
    "    # Сложные именованные сущности\n",
    "    \"Купил новый Samsung Galaxy S24 Ultra в DNS на Ленинском проспекте, консультант Дмитрий Иванович всё объяснил#neutral\",\n",
    "    \"Ужинал в ресторане White Rabbit на Смоленской площади - шеф-повар Владимир Мухин превзошел ожидания#positive\",\n",
    "\n",
    "    # Опечатки и сленг\n",
    "    \"норм телек LG купил в эльдорадо, продавец норм чел был, всё рассказал про функции#positive\"\n",
    "]\n",
    "\n",
    "# TODO: Создайте DataFrame и проанализируйте проблемы в данных\n",
    "# Создайте DataFrame из списка raw_reviews\n",
    "# Добавьте колонку с правильными метками тональности для каждого отзыва\n",
    "# Проанализируйте и выведите список проблем, которые вы видите в данных\n",
    "\n",
    "# Проблемы:\n",
    "#     - повторяющиеся знаки препинания\n",
    "#     - ошибки\n",
    "#     - эмодзи\n",
    "#     - названия с использованием знаков Яндекс.Еде, re:Store\n",
    "#     - эмоции через знаки\n",
    "\n",
    "# Подумайте: какие проблемы могут повлиять на качество анализа?\n",
    "\n",
    "# Ваш код здесь:\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = None\n",
    "df['mark'] = None\n",
    "\n",
    "for review in raw_reviews:\n",
    "\n",
    "    review_text, review_mark = review.split(\"#\")\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame({'text': [review_text], 'mark': [review_mark]})], ignore_index=True)\n",
    "\n",
    "\n",
    "# Анализ структуры данных\n",
    "print(\"Структура данных:\")\n",
    "print(f\"Количество отзывов: {df.shape[0]}\")\n",
    "print(f\"Колонки: {list(df.columns)}\")\n",
    "\n",
    "print(\"\\nДлина текстов отзывов:\")\n",
    "df[\"text_length\"] = df[\"text\"].str.len()\n",
    "print(f\"Средняя длина: {df['text_length'].mean():.1f} символов\")\n",
    "print(f\"Минимальная: {df['text_length'].min()} символов\")\n",
    "print(f\"Максимальная: {df['text_length'].max()} символов\")\n",
    "\n",
    "print(f\"Загружено {df.shape[0]} отзывов из общего списка:\")\n",
    "df.head()\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Структура данных:\n",
      "Количество отзывов: 15\n",
      "Колонки: ['text', 'mark']\n",
      "\n",
      "Длина текстов отзывов:\n",
      "Средняя длина: 94.1 символов\n",
      "Минимальная: 78 символов\n",
      "Максимальная: 114 символов\n",
      "Загружено 15 отзывов из общего списка:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                text      mark  text_length\n",
       "0  отличный iphone 14 PRO!!!  купил в магазине  a...  positive           78\n",
       "1  УЖАСНОЕ обслуживание в сбербанке на красной пл...  negative           90\n",
       "2  Спасибо огромное сотрудникам МТС за то что 3 ч...  negative           96\n",
       "3  Какой замечательный сервис в Пятерочке - касса...  negative          104\n",
       "4  iPhone 13 хороший телефон, но цена кусается. В...   neutral           80"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>mark</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>отличный iphone 14 PRO!!!  купил в магазине  a...</td>\n",
       "      <td>positive</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>УЖАСНОЕ обслуживание в сбербанке на красной пл...</td>\n",
       "      <td>negative</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Спасибо огромное сотрудникам МТС за то что 3 ч...</td>\n",
       "      <td>negative</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Какой замечательный сервис в Пятерочке - касса...</td>\n",
       "      <td>negative</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iPhone 13 хороший телефон, но цена кусается. В...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "rcowvTCc9krc"
   },
   "source": [
    "### Задание 1.2: Очистка и нормализация данных\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-k8nmeXq9krc",
    "ExecuteTime": {
     "end_time": "2025-08-24T09:23:47.054897Z",
     "start_time": "2025-08-24T09:23:47.050620Z"
    }
   },
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    if not text or pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    text = re.sub(r\"[^\\w\\s\\-.,!?;:()]\", \"\", text)\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = text.strip()\n",
    "\n",
    "    text = re.sub(r\"[.]{2,}\", \".\", text)\n",
    "    text = re.sub(r\"[!]{2,}\", \"!\", text)\n",
    "    text = re.sub(r\"[?]{2,}\", \"?\", text)\n",
    "\n",
    "    if text:\n",
    "        text = text[0].upper() + text[1:].lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "df[\"cleaned_text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "print(f\"\\nСредняя длина до очистки: {df['text'].str.len().mean():.1f}\")\n",
    "print(f\"Средняя длина после очистки: {df['cleaned_text'].str.len().mean():.1f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Средняя длина до очистки: 94.1\n",
      "Средняя длина после очистки: 93.5\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "Qt94ZTra9krc"
   },
   "source": [
    "### Задание 1.3: Использование готовых моделей HuggingFace\n"
   ]
  },
  {
   "metadata": {
    "id": "KGHpEYz_9krd",
    "ExecuteTime": {
     "end_time": "2025-08-24T10:20:41.624170Z",
     "start_time": "2025-08-24T10:20:38.855888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "# TODO: Загрузите готовые модели HuggingFace для анализа тональности и NER\n",
    "# Исследуйте HuggingFace Hub и найдите подходящие русскоязычные модели для:\n",
    "# - Анализа тональности (sentiment analysis)\n",
    "# - Извлечения именованных сущностей (NER)\n",
    "#\n",
    "# Используйте функцию pipeline() из библиотеки transformers\n",
    "# Обратите внимание на параметры модели и токенизатора\n",
    "\n",
    "# Ваш код для загрузки моделей:\n",
    "\n",
    "def analyze_with_huggingface(texts: List[str]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Анализ текстов с помощью готовых моделей HuggingFace\n",
    "    \"\"\"\n",
    "    # TODO: Реализуйте функцию анализа\n",
    "    # Для каждого текста:\n",
    "    # 1. Примените модель анализа тональности\n",
    "    # 2. Примените модель NER\n",
    "    # 3. Соберите результаты в структурированном виде\n",
    "    # 4. Верните список словарей с результатами\n",
    "\n",
    "    sentiment_model = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=\"blanchefort/rubert-base-cased-sentiment-rusentiment\",\n",
    "        return_all_scores=True\n",
    "    )\n",
    "\n",
    "    ner_model_id = \"r1char9/ner-rubert-tiny-RuNews\"\n",
    "\n",
    "    label2id = {\n",
    "        'O': 0,\n",
    "        'B-GEOPOLIT': 1, 'I-GEOPOLIT': 2,\n",
    "        'B-MEDIA': 3,    'I-MEDIA': 4,\n",
    "        'B-LOC': 5,      'I-LOC': 6,\n",
    "        'B-ORG': 7,      'I-ORG': 8,\n",
    "        'B-PER': 9,      'I-PER': 10\n",
    "    }\n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "    ner_model = AutoModelForTokenClassification.from_pretrained(\n",
    "        ner_model_id,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "\n",
    "    ner_pipeline = pipeline(\n",
    "        \"ner\",\n",
    "        model=ner_model,\n",
    "        tokenizer=AutoTokenizer.from_pretrained(ner_model_id),\n",
    "        aggregation_strategy=\"simple\"\n",
    "    )\n",
    "\n",
    "    label_mapping = {\n",
    "        \"POSITIVE\": \"positive\",\n",
    "        \"NEGATIVE\": \"negative\",\n",
    "        \"NEUTRAL\": \"neutral\"\n",
    "    }\n",
    "\n",
    "    for text in texts:\n",
    "\n",
    "        result = sentiment_model(text)\n",
    "\n",
    "        print(f\"Входной текст: {text}\")\n",
    "\n",
    "        if result and len(result[0]) > 0:\n",
    "            best_sentiment = max(result[0], key=lambda x: x[\"score\"])\n",
    "\n",
    "            sentiment = label_mapping.get(best_sentiment[\"label\"].upper(), best_sentiment[\"label\"].lower())\n",
    "\n",
    "            print(f\"Тональность: {sentiment}\")\n",
    "\n",
    "            ner_entity = ner_pipeline(text)\n",
    "            entity = []\n",
    "\n",
    "            for ner in ner_entity:\n",
    "                entity.append(ner['word'])\n",
    "\n",
    "            print(f\"Найденные сущности: {entity}\")\n",
    "\n",
    "\n",
    "analyze_with_huggingface(df[\"cleaned_text\"])\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входной текст: Отличный iphone 14 pro! купил в магазине apple на тверской . камера супер\n",
      "Тональность: positive\n",
      "Найденные сущности: []\n",
      "Входной текст: Ужасное обслуживание в сбербанке на красной площади. менеджер иван петров вобще не помог(\n",
      "Тональность: negative\n",
      "Найденные сущности: []\n",
      "Входной текст: Спасибо огромное сотрудникам мтс за то что 3 часа держали меня в очереди! просто восхитительно\n",
      "Тональность: positive\n",
      "Найденные сущности: []\n",
      "Входной текст: Какой замечательный сервис в пятерочке - касса сломалась прямо передо мной, а персонал даже не извинился\n",
      "Тональность: negative\n",
      "Найденные сущности: []\n",
      "Входной текст: Iphone 13 хороший телефон, но цена кусается. в целом доволен покупкой в re:store\n",
      "Тональность: neutral\n",
      "Найденные сущности: []\n",
      "Входной текст: Ресторан белуга красивый и атмосфера приятная, но официант максим был невнимателен\n",
      "Тональность: negative\n",
      "Найденные сущности: []\n",
      "Входной текст: Хотя tesla model y и дорогая машина, и сервис в рольф премиум иногда подводит, но в целом я очень доволен покупкой\n",
      "Тональность: positive\n",
      "Найденные сущности: ['tesla']\n",
      "Входной текст: Не могу сказать что отель ритц-карлтон плохой, просто ожидал большего за такие деньги\n",
      "Тональность: neutral\n",
      "Найденные сущности: []\n",
      "Входной текст: Заказал доставку в яндекс.еде из ресторана дача на рублевке - привезли холодное, но курьер андрей был вежливый\n",
      "Тональность: neutral\n",
      "Найденные сущности: []\n",
      "Входной текст: Macbook pro 16 работает как часы уже год, покупал в istore на арбате у консультанта елены\n",
      "Тональность: neutral\n",
      "Найденные сущности: ['Macbook', 'is']\n",
      "Входной текст: Сходил в кинотеатр октябрь посмотреть новый фильм marvel - ну такое себе, но попкорн вкусный был\n",
      "Тональность: positive\n",
      "Найденные сущности: ['marvel']\n",
      "Входной текст: Обслуживание в банке втб на тверской оставляет желать лучшего, хотя менеджер ольга старалась помочь\n",
      "Тональность: neutral\n",
      "Найденные сущности: ['##т']\n",
      "Входной текст: Купил новый samsung galaxy s24 ultra в dns на ленинском проспекте, консультант дмитрий иванович всё объяснил\n",
      "Тональность: neutral\n",
      "Найденные сущности: ['##sun', '##xy', 's24 ultra', 'd', '##ns', 'ленинском проспекте', 'д', '##рий', '##ванов']\n",
      "Входной текст: Ужинал в ресторане white rabbit на смоленской площади - шеф-повар владимир мухин превзошел ожидания\n",
      "Тональность: positive\n",
      "Найденные сущности: ['white rabbit', '##оленской площади']\n",
      "Входной текст: Норм телек lg купил в эльдорадо, продавец норм чел был, всё рассказал про функции\n",
      "Тональность: neutral\n",
      "Найденные сущности: ['Но', 'теле', 'lg', 'эльдорадо']\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "qWMo9XSi9krd"
   },
   "source": [
    "## 🤖 Часть 2: LLM API и Prompt Engineering (35% оценки)\n",
    "\n",
    "### Задание 2.1: Создание эффективных промптов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQD-5RUo9krd"
   },
   "outputs": [],
   "source": [
    "def create_prompts_for_llm() -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Создание базовых промптов для разных задач (один промпт на задачу)\n",
    "    \"\"\"\n",
    "    # TODO: Создайте эффективные промпты для NER и sentiment analysis\n",
    "    # Подумайте о структуре хорошего промпта:\n",
    "    # - Четкое описание задачи\n",
    "    # - Примеры входных и выходных данных\n",
    "    # - Формат ответа (JSON, текст и т.д.)\n",
    "    # - Особые требования (например, для русского языка)\n",
    "\n",
    "    # Создайте промпты для:\n",
    "    # 1. Извлечения именованных сущностей (NER)\n",
    "    # 2. Анализа тональности (sentiment analysis)\n",
    "\n",
    "    # Ваш код здесь:\n",
    "    pass\n",
    "\n",
    "# TODO: Протестируйте ваши промпты\n",
    "# Выведите созданные промпты и оцените их качество\n",
    "\n",
    "# TODO: Настройте OpenAI API\n",
    "# Установите API ключ через переменные окружения\n",
    "# Изучите документацию OpenAI API для Python\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Реализуйте функции для работы с OpenAI API\n",
    "# Создайте функции для:\n",
    "# 1. Вызова OpenAI API с промптом\n",
    "# 2. Обработки ответа от API\n",
    "# 3. Анализа текстов с помощью ваших промптов\n",
    "#\n",
    "# Подумайте о:\n",
    "# - Обработке ошибок API\n",
    "# - Формате запроса и ответа\n",
    "# - Параметрах модели (temperature, max_tokens)\n",
    "#\n",
    "# Протестируйте на нескольких текстах из датасета\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "VB2-dGNB9krd"
   },
   "source": [
    "### Задание 2.2: Сравнение результатов HuggingFace vs LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AuOOjL7L9krd"
   },
   "outputs": [],
   "source": [
    "# TODO: Сравните результаты HuggingFace моделей с LLM на одних и тех же текстах\n",
    "# Создайте сравнительный анализ:\n",
    "# 1. Соберите результаты обеих подходов в структурированном виде\n",
    "# 2. Сравните точность анализа тональности\n",
    "# 3. Сравните качество извлечения сущностей\n",
    "# 4. Проанализируйте время выполнения\n",
    "# 5. Оцените простоту использования\n",
    "#\n",
    "# Создайте визуализации для сравнения:\n",
    "# - Точность по разным метрикам\n",
    "# - Время обработки\n",
    "# - Количество найденных сущностей\n",
    "#\n",
    "# Сделайте выводы о том, когда лучше использовать каждый подход\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "SWToqoJY9krd"
   },
   "source": [
    "## 📚 Часть 3: Подготовка данных для Fine-tuning LLM (20% оценки)\n",
    "\n",
    "### Задание 3.1: Создание instruction-following датасета\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQyRs3Al9krd"
   },
   "outputs": [],
   "source": [
    "### Задание 2.3: Анализ сложных случаев\n",
    "\n",
    "# Выберем специально сложные примеры для демонстрации преимуществ LLM\n",
    "complex_cases = [\n",
    "    \"Спасибо огромное сотрудникам МТС за то что 3 часа держали меня в очереди! Просто восхитительно 👏\",\n",
    "    \"iPhone 13 хороший телефон, но цена кусается. В целом доволен покупкой в re:Store\",\n",
    "    \"Хотя Tesla Model Y и дорогая машина, и сервис в Рольф Премиум иногда подводит, но в целом я очень доволен покупкой\",\n",
    "    \"норм телек LG купил в эльдорадо, продавец норм чел был, всё рассказал про функции\"\n",
    "]\n",
    "\n",
    "print(\"Анализ сложных случаев:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TODO: Сравните результаты HuggingFace и OpenAI на сложных случаях\n",
    "# for i, text in enumerate(complex_cases):\n",
    "#     print(f\"\\nПример {i+1}: {text}\")\n",
    "#     # hf_result = sentiment_pipeline(text)\n",
    "#     # openai_result = analyze_with_openai([text])\n",
    "#     # print(f\"HuggingFace: {hf_result}\")\n",
    "#     # print(f\"OpenAI: {openai_result}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uH7Mc7zL9kre"
   },
   "outputs": [],
   "source": [
    "### Задание 2.4: Количественное сравнение точности\n",
    "\n",
    "# Создаем расширенный набор для тестирования с правильными ответами\n",
    "test_cases_with_labels = [\n",
    "    # Сарказм и ирония - должны быть NEGATIVE\n",
    "    (\"Спасибо огромное сотрудникам МТС за то что 3 часа держали меня в очереди! Просто восхитительно 👏\", \"NEGATIVE\"),\n",
    "    (\"Какой замечательный сервис в Пятерочке - касса сломалась прямо передо мной, а персонал даже не извинился\", \"NEGATIVE\"),\n",
    "\n",
    "    # Смешанные эмоции - должны быть NEUTRAL или зависеть от преобладающего тона\n",
    "    (\"iPhone 13 хороший телефон, но цена кусается. В целом доволен покупкой в re:Store\", \"NEUTRAL\"),\n",
    "    (\"Ресторан Белуга красивый и атмосфера приятная, но официант Максим был невнимателен\", \"NEUTRAL\"),\n",
    "\n",
    "    # Сложные структуры - требуют понимания контекста\n",
    "    (\"Хотя Tesla Model Y и дорогая машина, и сервис в Рольф Премиум иногда подводит, но в целом я очень доволен покупкой\", \"POSITIVE\"),\n",
    "    (\"Не могу сказать что отель Ритц-Карлтон плохой, просто ожидал большего за такие деньги\", \"NEUTRAL\"),\n",
    "\n",
    "    # Неформальная речь и сленг\n",
    "    (\"норм телек LG купил в эльдорадо, продавец норм чел был, всё рассказал про функции\", \"POSITIVE\"),\n",
    "    (\"Сходил в кинотеатр Октябрь посмотреть новый фильм Marvel - ну такое себе, но попкорн вкусный был\", \"NEUTRAL\"),\n",
    "\n",
    "    # Простые случаи для контроля\n",
    "    (\"отличный iphone 14 PRO!!! купил в магазине apple на тверской 😊. Камера супер\", \"POSITIVE\"),\n",
    "    (\"УЖАСНОЕ обслуживание в сбербанке на красной площади.. менеджер иван петров вобще не помог(\", \"NEGATIVE\")\n",
    "]\n",
    "\n",
    "# TODO: Рассчитайте точность для каждой модели\n",
    "# hf_correct = 0\n",
    "# openai_correct = 0\n",
    "# total = len(test_cases_with_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-62VRMQX9kre"
   },
   "outputs": [],
   "source": [
    "### Задание 2.5: Визуализация сравнения моделей\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Создайте визуализацию сравнения точности моделей\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# # Создайте графики сравнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-RBvP9I9kre"
   },
   "outputs": [],
   "source": [
    "def create_instruction_dataset(df: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Создание датасета в формате instruction-following для fine-tuning LLM\n",
    "    \"\"\"\n",
    "    # TODO: Создайте структурированный датасет для fine-tuning LLM\n",
    "    # Подумайте о структуре instruction-following датасета:\n",
    "    # - Какие поля должны быть в каждом примере?\n",
    "    # - Как сформулировать инструкции для модели?\n",
    "    # - Какие типы задач включить (sentiment, NER, etc.)?\n",
    "    # - Как структурировать ответы модели?\n",
    "    #\n",
    "    # Создайте несколько примеров для разных задач\n",
    "\n",
    "    pass\n",
    "\n",
    "# TODO: Протестируйте созданный датасет\n",
    "# Создайте и проанализируйте instruction dataset\n",
    "# Выведите примеры в читаемом формате\n",
    "# Проанализируйте распределение типов задач\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "60wLUwgM9kre"
   },
   "source": [
    "### Задание 3.2: Сериализация данных в формате для LLM платформ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-8GLE5A9kre"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# TODO: Реализуйте сохранение данных в форматах для fine-tuning\n",
    "# Создайте функции для сохранения данных в форматах:\n",
    "# 1. JSONL формат для OpenAI fine-tuning API\n",
    "# 2. CSV формат для общего использования\n",
    "#\n",
    "# Изучите требования к форматам:\n",
    "# - Какая структура нужна для OpenAI fine-tuning?\n",
    "# - Как правильно структурировать messages?\n",
    "# - Какие поля обязательны?\n",
    "#\n",
    "# Протестируйте сохранение и загрузку данных\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
